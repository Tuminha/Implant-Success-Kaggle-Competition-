{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü¶∑ Dental Implant 10-Year Survival Prediction\n",
        "\n",
        "## Notebook 08: TabPFN - Foundation Model for Tabular Data\n",
        "\n",
        "**Objective:** Test TabPFN, a transformer-based foundation model that reportedly beats tree-based methods on small-to-medium datasets.\n",
        "\n",
        "---\n",
        "\n",
        "### üî¨ What is TabPFN?\n",
        "\n",
        "TabPFN (Tabular Prior-data Fitted Network) is a **foundation model for tabular data** published in [Nature (2025)](https://nature.com/articles/s41586-024-08328-6).\n",
        "\n",
        "**Key Features:**\n",
        "- üöÄ **5,000√ó faster** than tuned CatBoost (2.8s vs 4h)\n",
        "- üéØ **Beats XGBoost, CatBoost, Random Forest** on small datasets\n",
        "- üß† **No hyperparameter tuning needed** - it's a pre-trained foundation model\n",
        "- üìä **Optimized for datasets ‚â§50,000 rows** - perfect for our ~7,000 samples!\n",
        "- ‚úÖ **Handles missing values natively**\n",
        "- üîÑ **Single forward pass** - no gradient descent at inference\n",
        "\n",
        "**How it works:**\n",
        "- Trained on 100M+ synthetic datasets from causal graphs\n",
        "- Uses two-way attention (across features & samples)\n",
        "- \"The transformer has basically learned to do supervised learning\"\n",
        "\n",
        "---\n",
        "\n",
        "### üìö References\n",
        "- [GitHub: PriorLabs/TabPFN](https://github.com/PriorLabs/TabPFN)\n",
        "- [Nature Paper](https://nature.com/articles/s41586-024-08328-6)\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ö†Ô∏è BEFORE RUNNING: Gated Model Access Required!\n",
        "\n",
        "TabPFN v2.5 is a **gated model** on HuggingFace. You must:\n",
        "\n",
        "1. **Visit** [https://huggingface.co/Prior-Labs/tabpfn_2_5](https://huggingface.co/Prior-Labs/tabpfn_2_5)\n",
        "2. **Click \"Agree and access repository\"** to accept the license\n",
        "3. **Authenticate** via `hf auth login` in terminal\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 1. Setup: Install TabPFN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tabpfn in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (6.0.6)\n",
            "Requirement already satisfied: torch<3,>=2.1 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tabpfn) (2.8.0)\n",
            "Requirement already satisfied: numpy<3,>=1.21.6 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tabpfn) (2.3.5)\n",
            "Requirement already satisfied: scikit-learn<1.8,>=1.2.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tabpfn) (1.7.2)\n",
            "Requirement already satisfied: typing_extensions>=4.12.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tabpfn) (4.15.0)\n",
            "Requirement already satisfied: scipy<2,>=1.11.1 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tabpfn) (1.16.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tabpfn) (2.3.2)\n",
            "Requirement already satisfied: einops<0.9,>=0.2.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tabpfn) (0.8.1)\n",
            "Requirement already satisfied: huggingface-hub<2,>=0.19.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tabpfn) (0.35.3)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /Users/franciscoteixeirabarbosa/.local/lib/python3.11/site-packages (from tabpfn) (2.11.10)\n",
            "Requirement already satisfied: pydantic-settings>=2.10.1 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tabpfn) (2.11.0)\n",
            "Requirement already satisfied: eval-type-backport>=0.2.2 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tabpfn) (0.3.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tabpfn) (1.5.2)\n",
            "Requirement already satisfied: tabpfn-common-utils>=0.2.7 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tabpfn-common-utils[telemetry-interactive]>=0.2.7->tabpfn) (0.2.10)\n",
            "Requirement already satisfied: pyobjc-framework-Metal in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tabpfn) (12.1)\n",
            "Requirement already satisfied: kditransform>=1.2 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tabpfn) (1.2.0)\n",
            "Requirement already satisfied: filelock in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<2,>=0.19.0->tabpfn) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<2,>=0.19.0->tabpfn) (2025.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<2,>=0.19.0->tabpfn) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<2,>=0.19.0->tabpfn) (6.0.2)\n",
            "Requirement already satisfied: requests in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<2,>=0.19.0->tabpfn) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<2,>=0.19.0->tabpfn) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<2,>=0.19.0->tabpfn) (1.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pandas<3,>=1.4.0->tabpfn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pandas<3,>=1.4.0->tabpfn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pandas<3,>=1.4.0->tabpfn) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from scikit-learn<1.8,>=1.2.0->tabpfn) (3.6.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from torch<3,>=2.1->tabpfn) (1.14.0)\n",
            "Requirement already satisfied: networkx in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from torch<3,>=2.1->tabpfn) (3.5)\n",
            "Requirement already satisfied: jinja2 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from torch<3,>=2.1->tabpfn) (3.1.6)\n",
            "Requirement already satisfied: numba>=0.48 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from kditransform>=1.2->tabpfn) (0.62.1)\n",
            "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from numba>=0.48->kditransform>=1.2->tabpfn) (0.45.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/franciscoteixeirabarbosa/.local/lib/python3.11/site-packages (from pydantic>=2.8.0->tabpfn) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /Users/franciscoteixeirabarbosa/.local/lib/python3.11/site-packages (from pydantic>=2.8.0->tabpfn) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/franciscoteixeirabarbosa/.local/lib/python3.11/site-packages (from pydantic>=2.8.0->tabpfn) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pydantic-settings>=2.10.1->tabpfn) (1.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->tabpfn) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from sympy>=1.13.3->torch<3,>=2.1->tabpfn) (1.3.0)\n",
            "Requirement already satisfied: platformdirs>=4 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tabpfn-common-utils>=0.2.7->tabpfn-common-utils[telemetry-interactive]>=0.2.7->tabpfn) (4.4.0)\n",
            "Requirement already satisfied: posthog~=6.7 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tabpfn-common-utils>=0.2.7->tabpfn-common-utils[telemetry-interactive]>=0.2.7->tabpfn) (6.9.3)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from posthog~=6.7->tabpfn-common-utils>=0.2.7->tabpfn-common-utils[telemetry-interactive]>=0.2.7->tabpfn) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from posthog~=6.7->tabpfn-common-utils>=0.2.7->tabpfn-common-utils[telemetry-interactive]>=0.2.7->tabpfn) (1.9.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests->huggingface-hub<2,>=0.19.0->tabpfn) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests->huggingface-hub<2,>=0.19.0->tabpfn) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests->huggingface-hub<2,>=0.19.0->tabpfn) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests->huggingface-hub<2,>=0.19.0->tabpfn) (2025.11.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from jinja2->torch<3,>=2.1->tabpfn) (3.0.2)\n",
            "Requirement already satisfied: pyobjc-core>=12.1 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pyobjc-framework-Metal->tabpfn) (12.1)\n",
            "Requirement already satisfied: pyobjc-framework-Cocoa>=12.1 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pyobjc-framework-Metal->tabpfn) (12.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Install TabPFN (requires Python 3.9+)\n",
        "# !pip install tabpfn --upgrade\n",
        "\n",
        "# ‚ö†Ô∏è IMPORTANT: TabPFN v2.5 is a GATED MODEL on HuggingFace!\n",
        "# You MUST do these steps BEFORE running:\n",
        "# 1. Visit https://huggingface.co/Prior-Labs/tabpfn_2_5\n",
        "# 2. Click \"Agree and access repository\" to accept the license\n",
        "# 3. Run 'hf auth login' in terminal (or set HF_TOKEN env var)\n",
        "\n",
        "# Load .env file to get HF_TOKEN\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv('../.env')\n",
        "\n",
        "# Verify HuggingFace token is available\n",
        "if os.getenv('HF_TOKEN'):\n",
        "    print(\"‚úÖ HF_TOKEN found in environment\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è HF_TOKEN not found - run 'hf auth login' in terminal\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Libraries imported!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, roc_auc_score,\n",
        "    precision_recall_curve, average_precision_score, f1_score,\n",
        "    recall_score, precision_score, roc_curve\n",
        ")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Periospot Brand Colors\n",
        "COLORS = {\n",
        "    'periospot_blue': '#15365a',\n",
        "    'mystic_blue': '#003049',\n",
        "    'periospot_red': '#6c1410',\n",
        "    'crimson_blaze': '#a92a2a',\n",
        "    'vanilla_cream': '#f7f0da',\n",
        "    'black': '#000000',\n",
        "    'white': '#ffffff',\n",
        "    'periospot_yellow': '#ffc430',\n",
        "}\n",
        "\n",
        "periospot_palette = [COLORS['periospot_blue'], COLORS['crimson_blaze'], \n",
        "                     COLORS['mystic_blue'], COLORS['periospot_yellow']]\n",
        "\n",
        "# Configure matplotlib\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.titlesize'] = 16\n",
        "plt.rcParams['axes.labelsize'] = 12\n",
        "plt.rcParams['figure.facecolor'] = COLORS['white']\n",
        "plt.rcParams['axes.facecolor'] = COLORS['vanilla_cream']\n",
        "plt.rcParams['axes.edgecolor'] = COLORS['periospot_blue']\n",
        "\n",
        "sns.set_palette(periospot_palette)\n",
        "\n",
        "print(\"‚úÖ Libraries imported!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ TabPFN imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import TabPFN\n",
        "try:\n",
        "    from tabpfn import TabPFNClassifier\n",
        "    print(\"‚úÖ TabPFN imported successfully!\")\n",
        "    TABPFN_AVAILABLE = True\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå TabPFN not installed. Run: pip install tabpfn\")\n",
        "    print(f\"   Error: {e}\")\n",
        "    TABPFN_AVAILABLE = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 2. Load Data\n",
        "\n",
        "We'll use the standard processed data (one-hot encoded) since TabPFN handles numerical features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (7000, 27)\n",
            "Target distribution:\n",
            "1    6367\n",
            "0     633\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class imbalance ratio: 10.1:1\n"
          ]
        }
      ],
      "source": [
        "# Load processed training data\n",
        "X = pd.read_csv('../data/processed/X_train.csv')\n",
        "y = pd.read_csv('../data/processed/y_train.csv').values.ravel()\n",
        "\n",
        "print(f\"Dataset shape: {X.shape}\")\n",
        "print(f\"Target distribution:\")\n",
        "print(pd.Series(y).value_counts())\n",
        "print(f\"\\nClass imbalance ratio: {(y==1).sum() / (y==0).sum():.1f}:1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set: 5600 samples\n",
            "Validation set: 1400 samples\n"
          ]
        }
      ],
      "source": [
        "# Train/Validation split (same as other notebooks for fair comparison)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Validation set: {X_val.shape[0]} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 3. TabPFN - Default (No Class Weights)\n",
        "\n",
        "First, let's try TabPFN with default settings to establish a baseline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing TabPFN...\n",
            "(First run will download ~1GB model weights from HuggingFace)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "HuggingFace download failed.\n",
            "For commercial usage, we provide alternative download options for v2.5, please reach out to us at sales@priorlabs.ai.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Authentication error downloading from 'Prior-Labs/tabpfn_2_5'.\nThis model is gated and requires you to accept its terms.\n\nPlease follow these steps:\n1. Visit https://huggingface.co/Prior-Labs/tabpfn_2_5 in your browser and accept the terms of use.\n2. Log in to your Hugging Face account via the command line by running:\n   hf auth login\n(Alternatively, you can set the HF_TOKEN environment variable with a read token).\n\nFor detailed instructions, see https://docs.priorlabs.ai/how-to-access-gated-models",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:407\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[31mHTTPError\u001b[39m: 403 Client Error: Forbidden for url: https://huggingface.co/Prior-Labs/tabpfn_2_5/resolve/main/tabpfn-v2.5-classifier-v2.5_default.ckpt",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mGatedRepoError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/tabpfn/model_loading.py:217\u001b[39m, in \u001b[36m_try_huggingface_downloads\u001b[39m\u001b[34m(base_path, source, model_name, suppress_warnings)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    216\u001b[39m     \u001b[38;5;66;03m# Download model checkpoint\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     local_path = \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# Move model file to desired location\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/huggingface_hub/file_download.py:990\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    982\u001b[39m         warnings.warn(\n\u001b[32m    983\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`local_dir_use_symlinks` parameter is deprecated and will be ignored. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    984\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe process to download files to a local folder has been updated and do \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    987\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFor more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    988\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m990\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_local_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    991\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m    992\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    993\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m    994\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    995\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    996\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/huggingface_hub/file_download.py:1253\u001b[39m, in \u001b[36m_hf_hub_download_to_local_dir\u001b[39m\u001b[34m(local_dir, repo_id, repo_type, filename, revision, endpoint, etag_timeout, headers, proxies, token, cache_dir, force_download, local_files_only)\u001b[39m\n\u001b[32m   1252\u001b[39m     \u001b[38;5;66;03m# Otherwise => raise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1253\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/huggingface_hub/file_download.py:1658\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1653\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1654\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error.response.status_code == \u001b[32m401\u001b[39m\n\u001b[32m   1655\u001b[39m ):\n\u001b[32m   1656\u001b[39m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[32m   1657\u001b[39m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1658\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[32m   1659\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1660\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/huggingface_hub/file_download.py:1546\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1545\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1546\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/huggingface_hub/file_download.py:1463\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[39m\n\u001b[32m   1462\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1463\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1469\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1471\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1472\u001b[39m hf_raise_for_status(r)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/huggingface_hub/file_download.py:286\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/huggingface_hub/file_download.py:310\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    309\u001b[39m response = http_backoff(method=method, url=url, **params)\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:424\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    421\u001b[39m     message = (\n\u001b[32m    422\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    423\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(GatedRepoError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m error_message == \u001b[33m\"\u001b[39m\u001b[33mAccess to this resource is disabled.\u001b[39m\u001b[33m\"\u001b[39m:\n",
            "\u001b[31mGatedRepoError\u001b[39m: 403 Client Error. (Request ID: Root=1-69333471-4cba5ebc141632ce0e8d3084;5299e818-e137-4f69-a10c-151e9ddcc7ea)\n\nCannot access gated repo for url https://huggingface.co/Prior-Labs/tabpfn_2_5/resolve/main/tabpfn-v2.5-classifier-v2.5_default.ckpt.\nAccess to model Prior-Labs/tabpfn_2_5 is restricted and you are not in the authorized list. Visit https://huggingface.co/Prior-Labs/tabpfn_2_5 to ask for access.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m start_time = time.time()\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mtabpfn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m training_time = time.time() - start_time\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úÖ TabPFN trained in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds!\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/contextlib.py:81\u001b[39m, in \u001b[36mContextDecorator.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwds):\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._recreate_cm():\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:288\u001b[39m, in \u001b[36mtrack_model_call.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: Any, **kwargs: Any) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_safe_call_with_telemetry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_names\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:332\u001b[39m, in \u001b[36m_safe_call_with_telemetry\u001b[39m\u001b[34m(func, args, kwargs, model_method, param_names)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# Step 2: Run the actual function\u001b[39;00m\n\u001b[32m    331\u001b[39m start = time.perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    333\u001b[39m duration_ms = \u001b[38;5;28mint\u001b[39m((time.perf_counter() - start) * \u001b[32m1000\u001b[39m)\n\u001b[32m    335\u001b[39m \u001b[38;5;66;03m# Step 3: Send telemetry event\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/tabpfn/classifier.py:816\u001b[39m, in \u001b[36mTabPFNClassifier.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    813\u001b[39m     \u001b[38;5;28mself\u001b[39m.fit_mode = \u001b[33m\"\u001b[39m\u001b[33mfit_preprocessors\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    815\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodels_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.differentiable_input:\n\u001b[32m--> \u001b[39m\u001b[32m816\u001b[39m     byte_size, rng = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize_model_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    817\u001b[39m     ensemble_configs, X, y = \u001b[38;5;28mself\u001b[39m._initialize_dataset_preprocessing(X, y, rng)\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# already fitted and prompt_tuning mode: no cat. features\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/tabpfn/classifier.py:593\u001b[39m, in \u001b[36mTabPFNClassifier._initialize_model_variables\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    589\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_initialize_model_variables\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, np.random.Generator]:\n\u001b[32m    590\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Perform initialization of the model, return determined byte_size\u001b[39;00m\n\u001b[32m    591\u001b[39m \u001b[33;03m    and RNG object.\u001b[39;00m\n\u001b[32m    592\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minitialize_model_variables_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclassifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/tabpfn/base.py:526\u001b[39m, in \u001b[36minitialize_model_variables_helper\u001b[39m\u001b[34m(calling_instance, model_type)\u001b[39m\n\u001b[32m    516\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Set attributes on the given model to prepare it for inference.\u001b[39;00m\n\u001b[32m    517\u001b[39m \n\u001b[32m    518\u001b[39m \u001b[33;03mThis includes selecting the device and the inference precision.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    522\u001b[39m \u001b[33;03m    dtype, and rng is a NumPy random Generator for use during inference.\u001b[39;00m\n\u001b[32m    523\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    524\u001b[39m static_seed, rng = infer_random_state(calling_instance.random_state)\n\u001b[32m    525\u001b[39m models, architecture_configs, maybe_bardist, inference_config = (\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m     \u001b[43minitialize_tabpfn_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcalling_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pyright: ignore[reportArgumentType]\u001b[39;49;00m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwhich\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcalling_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pyright: ignore[reportArgumentType]\u001b[39;49;00m\n\u001b[32m    530\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    531\u001b[39m )\n\u001b[32m    532\u001b[39m calling_instance.models_ = models\n\u001b[32m    533\u001b[39m calling_instance.configs_ = architecture_configs\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/tabpfn/base.py:189\u001b[39m, in \u001b[36minitialize_tabpfn_model\u001b[39m\u001b[34m(model_path, which, fit_mode)\u001b[39m\n\u001b[32m    185\u001b[39m download_if_not_exists = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m which == \u001b[33m\"\u001b[39m\u001b[33mclassifier\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    188\u001b[39m     models, _, architecture_configs, inference_config = (\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m         \u001b[43mload_model_criterion_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pyright: ignore[reportArgumentType]\u001b[39;49;00m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# The classifier's bar distribution is not used\u001b[39;49;00m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheck_bar_distribution_criterion\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_trainset_representation\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfit_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_with_cache\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m            \u001b[49m\u001b[43mwhich\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclassifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m            \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdownload_if_not_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_if_not_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     )\n\u001b[32m    199\u001b[39m     norm_criterion = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/tabpfn/model_loading.py:556\u001b[39m, in \u001b[36mload_model_criterion_config\u001b[39m\u001b[34m(model_path, check_bar_distribution_criterion, cache_trainset_representation, which, version, download_if_not_exists)\u001b[39m\n\u001b[32m    547\u001b[39m     res = download_model(\n\u001b[32m    548\u001b[39m         path,\n\u001b[32m    549\u001b[39m         version=model_version,\n\u001b[32m    550\u001b[39m         which=cast(\u001b[33m\"\u001b[39m\u001b[33mLiteral[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mclassifier\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mregressor\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m, which),\n\u001b[32m    551\u001b[39m         model_name=resolved_model_names[i],\n\u001b[32m    552\u001b[39m     )\n\u001b[32m    553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m res != \u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    554\u001b[39m         \u001b[38;5;66;03m# Later: Add improved error handling here, reenabling\u001b[39;00m\n\u001b[32m    555\u001b[39m         \u001b[38;5;66;03m#  the old offline download (only raise when Gating)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m res[\u001b[32m0\u001b[39m]\n\u001b[32m    558\u001b[39m loaded_model, criterion, architecture_config, inference_config = load_model(\n\u001b[32m    559\u001b[39m     path=path,\n\u001b[32m    560\u001b[39m     cache_trainset_representation=cache_trainset_representation,\n\u001b[32m    561\u001b[39m )\n\u001b[32m    562\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_bar_distribution_criterion \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    563\u001b[39m     criterion,\n\u001b[32m    564\u001b[39m     FullSupportBarDistribution,\n\u001b[32m    565\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/tabpfn/model_loading.py:352\u001b[39m, in \u001b[36mdownload_model\u001b[39m\u001b[34m(to, version, which, model_name)\u001b[39m\n\u001b[32m    349\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [e]\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     \u001b[43m_try_huggingface_downloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuppress_warnings\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# noqa: BLE001\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/tabpfn/model_loading.py:266\u001b[39m, in \u001b[36m_try_huggingface_downloads\u001b[39m\u001b[34m(base_path, source, model_name, suppress_warnings)\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_auth_error:\n\u001b[32m    251\u001b[39m     auth_message = (\n\u001b[32m    252\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAuthentication error downloading from \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource.repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis model is gated and requires you to accept its terms.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    264\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.priorlabs.ai/how-to-access-gated-models\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    265\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(auth_message)  \u001b[38;5;66;03m# noqa: B904\u001b[39;00m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "\u001b[31mRuntimeError\u001b[39m: Authentication error downloading from 'Prior-Labs/tabpfn_2_5'.\nThis model is gated and requires you to accept its terms.\n\nPlease follow these steps:\n1. Visit https://huggingface.co/Prior-Labs/tabpfn_2_5 in your browser and accept the terms of use.\n2. Log in to your Hugging Face account via the command line by running:\n   hf auth login\n(Alternatively, you can set the HF_TOKEN environment variable with a read token).\n\nFor detailed instructions, see https://docs.priorlabs.ai/how-to-access-gated-models"
          ]
        }
      ],
      "source": [
        "if TABPFN_AVAILABLE:\n",
        "    # Initialize TabPFN (will download model weights on first run)\n",
        "    print(\"Initializing TabPFN...\")\n",
        "    print(\"(First run will download ~1GB model weights from HuggingFace)\")\n",
        "    \n",
        "    tabpfn = TabPFNClassifier(\n",
        "        device='cpu',  # Use 'cuda' if you have a GPU\n",
        "        # N_ensemble_configurations=32  # More ensembles = better but slower\n",
        "    )\n",
        "    \n",
        "    # Time the training\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Fit the model\n",
        "    tabpfn.fit(X_train, y_train)\n",
        "    \n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"\\n‚úÖ TabPFN trained in {training_time:.2f} seconds!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è TabPFN not available. Please install with: pip install tabpfn\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if TABPFN_AVAILABLE:\n",
        "    # Make predictions\n",
        "    y_pred_default = tabpfn.predict(X_val)\n",
        "    y_pred_proba_default = tabpfn.predict_proba(X_val)[:, 1]\n",
        "    \n",
        "    # Calculate metrics\n",
        "    print(\"=\" * 60)\n",
        "    print(\"TabPFN (Default) - Classification Report\")\n",
        "    print(\"=\" * 60)\n",
        "    print(classification_report(y_val, y_pred_default, target_names=['Failure', 'Survival']))\n",
        "    \n",
        "    # Key metrics\n",
        "    recall_failure_default = recall_score(y_val, y_pred_default, pos_label=0)\n",
        "    recall_survival_default = recall_score(y_val, y_pred_default, pos_label=1)\n",
        "    f1_macro_default = f1_score(y_val, y_pred_default, average='macro')\n",
        "    roc_auc_default = roc_auc_score(y_val, y_pred_proba_default)\n",
        "    pr_auc_default = average_precision_score(y_val, y_pred_proba_default)\n",
        "    \n",
        "    print(f\"\\nüìä Key Metrics:\")\n",
        "    print(f\"   Failure Recall: {recall_failure_default*100:.1f}%\")\n",
        "    print(f\"   Survival Recall: {recall_survival_default*100:.1f}%\")\n",
        "    print(f\"   F1 (Macro): {f1_macro_default:.4f}\")\n",
        "    print(f\"   ROC-AUC: {roc_auc_default:.4f}\")\n",
        "    print(f\"   PR-AUC: {pr_auc_default:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 4. TabPFN - Threshold Optimization\n",
        "\n",
        "Since TabPFN doesn't have built-in class weights like CatBoost, we can optimize the prediction threshold to improve failure recall.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if TABPFN_AVAILABLE:\n",
        "    # Find optimal threshold for failure recall\n",
        "    thresholds = np.arange(0.1, 0.9, 0.05)\n",
        "    results = []\n",
        "    \n",
        "    for thresh in thresholds:\n",
        "        y_pred_thresh = (y_pred_proba_default >= thresh).astype(int)\n",
        "        recall_fail = recall_score(y_val, y_pred_thresh, pos_label=0)\n",
        "        recall_surv = recall_score(y_val, y_pred_thresh, pos_label=1)\n",
        "        f1 = f1_score(y_val, y_pred_thresh, average='macro')\n",
        "        results.append({\n",
        "            'threshold': thresh,\n",
        "            'failure_recall': recall_fail,\n",
        "            'survival_recall': recall_surv,\n",
        "            'f1_macro': f1\n",
        "        })\n",
        "    \n",
        "    results_df = pd.DataFrame(results)\n",
        "    \n",
        "    # Plot threshold analysis\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    ax.plot(results_df['threshold'], results_df['failure_recall'], \n",
        "            label='Failure Recall', color=COLORS['crimson_blaze'], linewidth=2)\n",
        "    ax.plot(results_df['threshold'], results_df['survival_recall'], \n",
        "            label='Survival Recall', color=COLORS['periospot_blue'], linewidth=2)\n",
        "    ax.plot(results_df['threshold'], results_df['f1_macro'], \n",
        "            label='F1 (Macro)', color=COLORS['periospot_yellow'], linewidth=2, linestyle='--')\n",
        "    \n",
        "    ax.set_xlabel('Prediction Threshold')\n",
        "    ax.set_ylabel('Score')\n",
        "    ax.set_title('TabPFN: Threshold Optimization', fontsize=14, fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.axvline(x=0.5, color='gray', linestyle=':', label='Default (0.5)')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../figures/tabpfn_threshold_analysis.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # Find best threshold for balanced recall\n",
        "    results_df['balance'] = results_df['failure_recall'] + results_df['survival_recall']\n",
        "    best_idx = results_df['f1_macro'].idxmax()\n",
        "    best_threshold = results_df.loc[best_idx, 'threshold']\n",
        "    \n",
        "    print(f\"\\nüéØ Best threshold for F1 (Macro): {best_threshold:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if TABPFN_AVAILABLE:\n",
        "    # Apply optimized threshold\n",
        "    y_pred_optimized = (y_pred_proba_default >= best_threshold).astype(int)\n",
        "    \n",
        "    # Calculate metrics with optimized threshold\n",
        "    recall_failure_opt = recall_score(y_val, y_pred_optimized, pos_label=0)\n",
        "    recall_survival_opt = recall_score(y_val, y_pred_optimized, pos_label=1)\n",
        "    f1_macro_opt = f1_score(y_val, y_pred_optimized, average='macro')\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(f\"TabPFN (Threshold={best_threshold:.2f}) - Classification Report\")\n",
        "    print(\"=\" * 60)\n",
        "    print(classification_report(y_val, y_pred_optimized, target_names=['Failure', 'Survival']))\n",
        "    \n",
        "    print(f\"\\nüìä Key Metrics (Optimized):\")\n",
        "    print(f\"   Failure Recall: {recall_failure_opt*100:.1f}%\")\n",
        "    print(f\"   Survival Recall: {recall_survival_opt*100:.1f}%\")\n",
        "    print(f\"   F1 (Macro): {f1_macro_opt:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 5. Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if TABPFN_AVAILABLE:\n",
        "    # Create confusion matrix comparison\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Default TabPFN\n",
        "    cm_default = confusion_matrix(y_val, y_pred_default)\n",
        "    sns.heatmap(cm_default, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
        "                xticklabels=['Pred Failure', 'Pred Survival'],\n",
        "                yticklabels=['Actual Failure', 'Actual Survival'])\n",
        "    axes[0].set_title(f'TabPFN (Default)\\n{recall_failure_default*100:.1f}% Failure Recall',\n",
        "                      fontsize=12, color=COLORS['periospot_blue'], fontweight='bold')\n",
        "    \n",
        "    # Optimized TabPFN\n",
        "    cm_opt = confusion_matrix(y_val, y_pred_optimized)\n",
        "    sns.heatmap(cm_opt, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n",
        "                xticklabels=['Pred Failure', 'Pred Survival'],\n",
        "                yticklabels=['Actual Failure', 'Actual Survival'])\n",
        "    axes[1].set_title(f'TabPFN (Threshold={best_threshold:.2f})\\n{recall_failure_opt*100:.1f}% Failure Recall',\n",
        "                      fontsize=12, color=COLORS['mystic_blue'], fontweight='bold')\n",
        "    \n",
        "    plt.suptitle('TabPFN: Impact of Threshold Optimization', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../figures/tabpfn_comparison.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if TABPFN_AVAILABLE:\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_val, y_pred_proba_default)\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    ax.plot(fpr, tpr, color=COLORS['periospot_yellow'], linewidth=2,\n",
        "            label=f'TabPFN (AUC = {roc_auc_default:.4f})')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "    ax.set_xlabel('False Positive Rate')\n",
        "    ax.set_ylabel('True Positive Rate')\n",
        "    ax.set_title('TabPFN - ROC Curve', fontsize=14, fontweight='bold')\n",
        "    ax.legend(loc='lower right')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../figures/tabpfn_roc_curve.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 6. Save Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if TABPFN_AVAILABLE:\n",
        "    # Save results to JSON\n",
        "    results = {\n",
        "        'model': 'TabPFN (Optimized)',\n",
        "        'roc_auc': float(roc_auc_default),\n",
        "        'pr_auc': float(pr_auc_default),\n",
        "        'f1_macro': float(f1_macro_opt),\n",
        "        'accuracy': float((y_pred_optimized == y_val).mean()),\n",
        "        'recall_failure': float(recall_failure_opt),\n",
        "        'recall_survival': float(recall_survival_opt),\n",
        "        'threshold': float(best_threshold),\n",
        "        'training_time_seconds': float(training_time)\n",
        "    }\n",
        "    \n",
        "    with open('../results/tabpfn_results.json', 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    \n",
        "    print(\"‚úÖ Results saved to ../results/tabpfn_results.json\")\n",
        "    print(\"\\nüìä Final Results:\")\n",
        "    for key, value in results.items():\n",
        "        print(f\"   {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### ‚úÖ TabPFN Analysis Complete!\n",
        "\n",
        "**Key Learnings:**\n",
        "\n",
        "1. **TabPFN is a Foundation Model:**\n",
        "   - Pre-trained on 100M+ synthetic datasets\n",
        "   - No hyperparameter tuning needed!\n",
        "   - Single forward pass for both \"training\" and prediction\n",
        "\n",
        "2. **Class Imbalance Handling:**\n",
        "   - TabPFN doesn't have built-in class weights\n",
        "   - Threshold optimization can improve failure recall\n",
        "   - Trade-off between failure and survival recall\n",
        "\n",
        "3. **Speed:**\n",
        "   - Training takes seconds (not hours like Optuna tuning!)\n",
        "   - Perfect for rapid prototyping and iteration\n",
        "\n",
        "**References:**\n",
        "- [GitHub: PriorLabs/TabPFN](https://github.com/PriorLabs/TabPFN)\n",
        "- [Nature Paper: Accurate predictions on small data with a tabular foundation model](https://nature.com/articles/s41586-024-08328-6)\n",
        "\n",
        "**Next Steps:**\n",
        "- Compare TabPFN results with CatBoost in `07_Model_Comparison.ipynb`\n",
        "- Consider ensemble of TabPFN + CatBoost for submission\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Codecademy ML",
      "language": "python",
      "name": "codeacademy"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
