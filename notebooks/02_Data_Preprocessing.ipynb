{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ¦· Dental Implant 10-Year Survival Prediction\n",
        "\n",
        "## Notebook 02: Data Preprocessing\n",
        "\n",
        "**Objective:** Clean the data, handle categorical features, and prepare it for model training. The processed data will be saved for use in the modeling notebooks.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸŽ¨ Setup: Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ… Libraries imported!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 1. Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Load the raw training data.\n",
        "# Hint: Use pd.read_csv() with the correct path to data/raw/train.csv\n",
        "df = ...\n",
        "\n",
        "# Display basic info\n",
        "print(f\"Shape: {df.shape}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Load the test data as well - we'll need to apply the same preprocessing.\n",
        "# Hint: The test data is at data/raw/test.csv\n",
        "df_test = ...\n",
        "\n",
        "print(f\"Test shape: {df_test.shape}\")\n",
        "df_test.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 2. Identify Column Types\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Identify the ID column, target column, and feature columns.\n",
        "# Hint: Usually there's an 'id' column that shouldn't be used as a feature.\n",
        "\n",
        "# Define column names\n",
        "id_col = ...  # e.g., 'id' or 'patient_id'\n",
        "target_col = 'implant_survival_10y'\n",
        "\n",
        "# Get all feature columns (everything except id and target)\n",
        "feature_cols = [col for col in df.columns if col not in [id_col, target_col]]\n",
        "\n",
        "print(f\"ID column: {id_col}\")\n",
        "print(f\"Target column: {target_col}\")\n",
        "print(f\"Feature columns ({len(feature_cols)}): {feature_cols}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Separate numerical and categorical features.\n",
        "# Hint: Use df[feature_cols].select_dtypes()\n",
        "\n",
        "numerical_cols = ...\n",
        "categorical_cols = ...\n",
        "\n",
        "print(f\"Numerical columns: {list(numerical_cols)}\")\n",
        "print(f\"Categorical columns: {list(categorical_cols)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 3. Handle Missing Values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Check for missing values in training data.\n",
        "# Hint: Use df.isnull().sum()\n",
        "print(\"Missing values in training data:\")\n",
        "...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: If there are missing values, decide how to handle them.\n",
        "# Options:\n",
        "# 1. For numerical columns: fill with median or mean\n",
        "#    df[col].fillna(df[col].median(), inplace=True)\n",
        "# 2. For categorical columns: fill with mode or a placeholder like 'Unknown'\n",
        "#    df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "# 3. Drop rows with missing values (not recommended if many rows are affected)\n",
        "\n",
        "# Example:\n",
        "# for col in numerical_cols:\n",
        "#     if df[col].isnull().sum() > 0:\n",
        "#         median_val = df[col].median()\n",
        "#         df[col].fillna(median_val, inplace=True)\n",
        "#         df_test[col].fillna(median_val, inplace=True)  # Use training median for test!\n",
        "\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 4. Feature Engineering & Selection (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Based on the EDA, decide if any new features should be created.\n",
        "# Examples of feature engineering:\n",
        "# - Age groups: df['age_group'] = pd.cut(df['age'], bins=[0, 30, 50, 70, 100], labels=['young', 'middle', 'senior', 'elderly'])\n",
        "# - Combining related features: df['total_risk'] = df['risk_factor_1'] + df['risk_factor_2']\n",
        "# - Interaction terms: df['age_x_smoking'] = df['age'] * df['smoking']\n",
        "\n",
        "# For now, we will proceed with all features.\n",
        "# Add your feature engineering code below if needed:\n",
        "\n",
        "...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Based on the EDA, decide if any features should be dropped.\n",
        "# Reasons to drop features:\n",
        "# - High correlation with other features (multicollinearity)\n",
        "# - No variance (constant values)\n",
        "# - Too many missing values\n",
        "# - Identified as irrelevant during EDA\n",
        "\n",
        "# Example:\n",
        "# cols_to_drop = ['irrelevant_feature']\n",
        "# df = df.drop(columns=cols_to_drop)\n",
        "# df_test = df_test.drop(columns=cols_to_drop)\n",
        "\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 5. Handle Categorical Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Look at unique values for each categorical feature.\n",
        "# This helps decide between label encoding and one-hot encoding.\n",
        "\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\n{col}: {df[col].nunique()} unique values\")\n",
        "    print(df[col].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Convert binary categorical features (e.g., 'gender', 'smoking') into numerical format (0 and 1).\n",
        "# Hint: You can use df['column'].map({'Value1': 0, 'Value2': 1})\n",
        "\n",
        "# Example for a binary column like 'gender':\n",
        "# df['gender'] = df['gender'].map({'Male': 0, 'Female': 1})\n",
        "# df_test['gender'] = df_test['gender'].map({'Male': 0, 'Female': 1})\n",
        "\n",
        "# Identify binary columns (columns with exactly 2 unique values)\n",
        "binary_cols = [col for col in categorical_cols if df[col].nunique() == 2]\n",
        "print(f\"Binary columns: {binary_cols}\")\n",
        "\n",
        "# TODO: Encode binary columns\n",
        "...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Apply one-hot encoding to multi-class categorical features.\n",
        "# Hint: Use pd.get_dummies() with drop_first=True to avoid multicollinearity.\n",
        "\n",
        "# Identify multi-class categorical columns\n",
        "multiclass_cols = [col for col in categorical_cols if df[col].nunique() > 2]\n",
        "print(f\"Multi-class columns for one-hot encoding: {multiclass_cols}\")\n",
        "\n",
        "# TODO: Apply one-hot encoding\n",
        "# df_processed = pd.get_dummies(df, columns=multiclass_cols, drop_first=True)\n",
        "# df_test_processed = pd.get_dummies(df_test, columns=multiclass_cols, drop_first=True)\n",
        "\n",
        "df_processed = ...\n",
        "df_test_processed = ...\n",
        "\n",
        "print(f\"Shape after encoding: {df_processed.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Make sure train and test have the same columns after one-hot encoding.\n",
        "# Hint: Sometimes test data might not have all categories that appear in training.\n",
        "\n",
        "# Get columns in train but not in test\n",
        "train_cols = set(df_processed.columns)\n",
        "test_cols = set(df_test_processed.columns)\n",
        "\n",
        "# Add missing columns to test with zeros\n",
        "missing_in_test = train_cols - test_cols\n",
        "for col in missing_in_test:\n",
        "    if col != target_col:  # Don't add target column to test\n",
        "        df_test_processed[col] = 0\n",
        "\n",
        "# Remove extra columns from test\n",
        "extra_in_test = test_cols - train_cols\n",
        "df_test_processed = df_test_processed.drop(columns=list(extra_in_test), errors='ignore')\n",
        "\n",
        "print(f\"Train columns: {df_processed.shape[1]}\")\n",
        "print(f\"Test columns: {df_test_processed.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 6. Separate Features and Target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Separate the features (X) from the target variable (y).\n",
        "# Don't include the ID column in features!\n",
        "\n",
        "# Get the final feature columns (exclude id and target)\n",
        "final_feature_cols = [col for col in df_processed.columns if col not in [id_col, target_col]]\n",
        "\n",
        "X = df_processed[final_feature_cols]\n",
        "y = df_processed[target_col]\n",
        "\n",
        "# For test data, keep the ID for submission and get features\n",
        "test_ids = df_test_processed[id_col] if id_col in df_test_processed.columns else df_test[id_col]\n",
        "X_test = df_test_processed[final_feature_cols]\n",
        "\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"y shape: {y.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 7. Save Processed Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Save the processed features (X) and target (y) to the /data/processed/ folder.\n",
        "# This will allow other notebooks to load the clean data directly.\n",
        "# Hint: Use the .to_csv(index=False) method.\n",
        "\n",
        "# Save training data\n",
        "X.to_csv('../data/processed/X_train.csv', index=False)\n",
        "y.to_csv('../data/processed/y_train.csv', index=False)\n",
        "\n",
        "# Save test data\n",
        "X_test.to_csv('../data/processed/X_test.csv', index=False)\n",
        "test_ids.to_csv('../data/processed/test_ids.csv', index=False)\n",
        "\n",
        "print(\"âœ… Processed data saved to /data/processed/ folder!\")\n",
        "print(f\"   - X_train.csv: {X.shape}\")\n",
        "print(f\"   - y_train.csv: {y.shape}\")\n",
        "print(f\"   - X_test.csv: {X_test.shape}\")\n",
        "print(f\"   - test_ids.csv: {test_ids.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Also save the list of feature names for reference.\n",
        "# This can be useful for feature importance analysis later.\n",
        "\n",
        "feature_names = pd.DataFrame({'feature_name': final_feature_cols})\n",
        "feature_names.to_csv('../data/processed/feature_names.csv', index=False)\n",
        "\n",
        "print(f\"Saved {len(final_feature_cols)} feature names.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 8. Quick Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Verify the saved data by loading it back and checking.\n",
        "\n",
        "X_check = pd.read_csv('../data/processed/X_train.csv')\n",
        "y_check = pd.read_csv('../data/processed/y_train.csv')\n",
        "\n",
        "print(f\"Loaded X_train shape: {X_check.shape}\")\n",
        "print(f\"Loaded y_train shape: {y_check.shape}\")\n",
        "print(f\"\\nFeature columns: {list(X_check.columns)}\")\n",
        "print(f\"\\nTarget distribution:\")\n",
        "print(y_check.value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### âœ… Data Preprocessing Complete!\n",
        "\n",
        "**Data has been saved to `/data/processed/`:**\n",
        "- `X_train.csv` - Training features\n",
        "- `y_train.csv` - Training target\n",
        "- `X_test.csv` - Test features\n",
        "- `test_ids.csv` - Test IDs for submission\n",
        "- `feature_names.csv` - List of feature names\n",
        "\n",
        "**Next Step:** Proceed to `03_Baseline_Models.ipynb` to train your first models!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ¦· Dental Implant 10-Year Survival Prediction\n",
        "\n",
        "## Notebook 02: Data Preprocessing\n",
        "\n",
        "**Objective:** Clean the data, handle categorical features, and prepare it for model training. The processed data will be saved for use in the modeling notebooks.\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
