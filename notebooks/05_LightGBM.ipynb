{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ¦· Dental Implant 10-Year Survival Prediction\n",
        "\n",
        "## Notebook 05: LightGBM Model\n",
        "\n",
        "**Objective:** Train and evaluate a LightGBM classifier - a fast, efficient gradient boosting framework that uses histogram-based algorithms.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸŽ¨ Setup: Import Libraries & Configure Plotting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, classification_report, roc_curve\n",
        "import lightgbm as lgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Periospot Brand Colors\n",
        "COLORS = {\n",
        "    'periospot_blue': '#15365a',\n",
        "    'mystic_blue': '#003049',\n",
        "    'periospot_red': '#6c1410',\n",
        "    'crimson_blaze': '#a92a2a',\n",
        "    'vanilla_cream': '#f7f0da',\n",
        "    'black': '#000000',\n",
        "    'white': '#ffffff',\n",
        "    'classic_periospot_blue': '#0031af',\n",
        "    'periospot_light_blue': '#0297ed',\n",
        "    'periospot_dark_blue': '#02011e',\n",
        "    'periospot_yellow': '#ffc430',\n",
        "    'periospot_bright_blue': '#1040dd'\n",
        "}\n",
        "\n",
        "periospot_palette = [COLORS['periospot_blue'], COLORS['crimson_blaze'], \n",
        "                     COLORS['periospot_light_blue'], COLORS['periospot_yellow']]\n",
        "\n",
        "# Configure matplotlib\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.titlesize'] = 16\n",
        "plt.rcParams['axes.labelsize'] = 12\n",
        "plt.rcParams['xtick.labelsize'] = 10\n",
        "plt.rcParams['ytick.labelsize'] = 10\n",
        "plt.rcParams['figure.facecolor'] = COLORS['white']\n",
        "plt.rcParams['axes.facecolor'] = COLORS['vanilla_cream']\n",
        "plt.rcParams['axes.edgecolor'] = COLORS['periospot_blue']\n",
        "\n",
        "sns.set_palette(periospot_palette)\n",
        "\n",
        "print(\"âœ… Libraries imported and plotting style configured!\")\n",
        "print(f\"LightGBM version: {lgb.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 1. Load Processed Data & Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the processed data\n",
        "X = pd.read_csv('../data/processed/X_train.csv')\n",
        "y = pd.read_csv('../data/processed/y_train.csv').values.ravel()\n",
        "\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"y shape: {y.shape}\")\n",
        "\n",
        "# Split into train and validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
        "print(f\"Validation set: {X_val.shape[0]} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 2. Train LightGBM Model\n",
        "\n",
        "LightGBM (Light Gradient Boosting Machine) is known for its speed and efficiency, especially with large datasets. It uses histogram-based algorithms.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Initialize the LightGBM Classifier with appropriate hyperparameters.\n",
        "# Hint: Use lgb.LGBMClassifier() with parameters like:\n",
        "#   - n_estimators: number of boosting rounds (e.g., 100)\n",
        "#   - max_depth: maximum tree depth (e.g., -1 for no limit, or specific value like 6)\n",
        "#   - learning_rate: step size shrinkage (e.g., 0.1)\n",
        "#   - num_leaves: max number of leaves in one tree (e.g., 31)\n",
        "#   - random_state: for reproducibility (42)\n",
        "\n",
        "lgb_model = lgb.LGBMClassifier(\n",
        "    n_estimators=...,\n",
        "    max_depth=...,\n",
        "    learning_rate=...,\n",
        "    num_leaves=...,\n",
        "    random_state=42,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "# TODO: Fit the model on the training data.\n",
        "# lgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
        "...\n",
        "\n",
        "print(\"âœ… LightGBM model trained!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 3. Evaluate LightGBM Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Make predictions on the validation set.\n",
        "\n",
        "y_pred_lgb = ...  # Class predictions\n",
        "y_pred_lgb_proba = ...  # Probability predictions (use [:, 1] for positive class)\n",
        "\n",
        "# TODO: Calculate metrics\n",
        "roc_auc_lgb = ...\n",
        "accuracy_lgb = ...\n",
        "\n",
        "print(f\"LightGBM Results:\")\n",
        "print(f\"  - ROC-AUC: {roc_auc_lgb:.4f}\")\n",
        "print(f\"  - Accuracy: {accuracy_lgb:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classification report and confusion matrix\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_pred_lgb))\n",
        "\n",
        "# Plot confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "cm = confusion_matrix(y_val, y_pred_lgb)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
        "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "ax.set_title('LightGBM - Confusion Matrix', fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('../figures/lgb_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot ROC curve\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_val, y_pred_lgb_proba)\n",
        "ax.plot(fpr, tpr, label=f'LightGBM (AUC = {roc_auc_lgb:.4f})', \n",
        "        color=COLORS['periospot_light_blue'], linewidth=2)\n",
        "ax.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title('LightGBM - ROC Curve', fontweight='bold')\n",
        "ax.legend(loc='lower right')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../figures/lgb_roc_curve.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 4. Feature Importance Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Visualize feature importance from LightGBM.\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': lgb_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "# Plot top 15 features\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "top_features = feature_importance.head(15)\n",
        "sns.barplot(data=top_features, x='importance', y='feature', \n",
        "            palette=periospot_palette, ax=ax)\n",
        "ax.set_title('LightGBM - Top 15 Feature Importances', fontweight='bold')\n",
        "ax.set_xlabel('Importance')\n",
        "ax.set_ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.savefig('../figures/lgb_feature_importance.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(feature_importance.head(10).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 5. Save Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the LightGBM results to a JSON file\n",
        "\n",
        "results_lgb = {\n",
        "    \"model\": \"LightGBM\",\n",
        "    \"roc_auc\": float(roc_auc_lgb),\n",
        "    \"accuracy\": float(accuracy_lgb),\n",
        "    \"hyperparameters\": {\n",
        "        \"n_estimators\": lgb_model.n_estimators,\n",
        "        \"max_depth\": lgb_model.max_depth,\n",
        "        \"learning_rate\": lgb_model.learning_rate,\n",
        "        \"num_leaves\": lgb_model.num_leaves\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('../results/lightgbm_results.json', 'w') as f:\n",
        "    json.dump(results_lgb, f, indent=2)\n",
        "\n",
        "print(\"âœ… Results saved to results/lightgbm_results.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### âœ… LightGBM Training Complete!\n",
        "\n",
        "**Next Steps:** \n",
        "- Try CatBoost in `06_CatBoost.ipynb`\n",
        "- Compare all models to select the best one for submission\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ¦· Dental Implant 10-Year Survival Prediction\n",
        "\n",
        "## Notebook 05: LightGBM Model\n",
        "\n",
        "**Objective:** Train and evaluate a LightGBM (Light Gradient Boosting Machine) classifier. LightGBM is known for its efficiency with large datasets and categorical features.\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
