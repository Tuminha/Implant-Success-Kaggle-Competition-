{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü¶∑ Dental Implant 10-Year Survival Prediction\n",
        "\n",
        "## Notebook 03: Baseline Models\n",
        "\n",
        "**Objective:** Train and evaluate baseline machine learning models (Logistic Regression and Random Forest) to establish a performance benchmark.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üé® Setup: Import Libraries & Configure Plotting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, classification_report, roc_curve\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Periospot Brand Colors\n",
        "COLORS = {\n",
        "    'periospot_blue': '#15365a',\n",
        "    'mystic_blue': '#003049',\n",
        "    'periospot_red': '#6c1410',\n",
        "    'crimson_blaze': '#a92a2a',\n",
        "    'vanilla_cream': '#f7f0da',\n",
        "    'black': '#000000',\n",
        "    'white': '#ffffff',\n",
        "    'classic_periospot_blue': '#0031af',\n",
        "    'periospot_light_blue': '#0297ed',\n",
        "    'periospot_dark_blue': '#02011e',\n",
        "    'periospot_yellow': '#ffc430',\n",
        "    'periospot_bright_blue': '#1040dd'\n",
        "}\n",
        "\n",
        "periospot_palette = [COLORS['periospot_blue'], COLORS['crimson_blaze'], \n",
        "                     COLORS['periospot_light_blue'], COLORS['periospot_yellow']]\n",
        "\n",
        "# Configure matplotlib\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.titlesize'] = 16\n",
        "plt.rcParams['axes.labelsize'] = 12\n",
        "plt.rcParams['xtick.labelsize'] = 10\n",
        "plt.rcParams['ytick.labelsize'] = 10\n",
        "plt.rcParams['figure.facecolor'] = COLORS['white']\n",
        "plt.rcParams['axes.facecolor'] = COLORS['vanilla_cream']\n",
        "plt.rcParams['axes.edgecolor'] = COLORS['periospot_blue']\n",
        "\n",
        "sns.set_palette(periospot_palette)\n",
        "\n",
        "print(\"‚úÖ Libraries imported and plotting style configured!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 1. Load Processed Data & Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Load the processed data (X.csv and y.csv) from the /data/processed/ folder.\n",
        "X = pd.read_csv('../data/processed/X_train.csv')\n",
        "y = pd.read_csv('../data/processed/y_train.csv').values.ravel()  # Convert to 1D array\n",
        "\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"y shape: {y.shape}\")\n",
        "print(f\"\\nTarget distribution:\")\n",
        "print(pd.Series(y).value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Split the data into training and validation sets (80/20 split).\n",
        "# Hint: Use train_test_split with test_size=0.2 and random_state=42.\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, \n",
        "    test_size=0.2, \n",
        "    random_state=42,\n",
        "    stratify=y  # Maintain class distribution\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Validation set: {X_val.shape[0]} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 2. Train & Evaluate Logistic Regression\n",
        "\n",
        "Logistic Regression is a simple, interpretable baseline model for binary classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Initialize the Logistic Regression model.\n",
        "# Hint: Use LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr_model = ...\n",
        "\n",
        "# TODO: Fit the model on the training data.\n",
        "# Hint: Use the .fit() method.\n",
        "...\n",
        "\n",
        "print(\"‚úÖ Logistic Regression model trained!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Make predictions on the validation set.\n",
        "# Hint: Use .predict() for class labels and .predict_proba() for probabilities.\n",
        "\n",
        "y_pred_lr = ...  # Class predictions\n",
        "y_pred_lr_proba = ...  # Probability predictions (use [:, 1] for positive class)\n",
        "\n",
        "# TODO: Calculate the ROC-AUC score.\n",
        "# Hint: Use roc_auc_score(y_val, y_pred_lr_proba)\n",
        "roc_auc_lr = ...\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_lr = ...\n",
        "\n",
        "print(f\"Logistic Regression Results:\")\n",
        "print(f\"  - ROC-AUC: {roc_auc_lr:.4f}\")\n",
        "print(f\"  - Accuracy: {accuracy_lr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Display the confusion matrix and classification report.\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_pred_lr))\n",
        "\n",
        "# Plot confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "cm = confusion_matrix(y_val, y_pred_lr)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
        "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "ax.set_title('Logistic Regression - Confusion Matrix', fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('../figures/lr_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Save the results to a JSON file in the /results/ folder.\n",
        "# The JSON should contain the model name and its metrics.\n",
        "\n",
        "results_lr = {\n",
        "    \"model\": \"LogisticRegression\",\n",
        "    \"roc_auc\": float(roc_auc_lr),\n",
        "    \"accuracy\": float(accuracy_lr)\n",
        "}\n",
        "\n",
        "with open('../results/logistic_regression_results.json', 'w') as f:\n",
        "    json.dump(results_lr, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ Results saved to results/logistic_regression_results.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 3. Train & Evaluate Random Forest\n",
        "\n",
        "Random Forest is an ensemble method that typically performs better than single decision trees.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Initialize the Random Forest Classifier.\n",
        "# Hint: Use RandomForestClassifier(n_estimators=100, random_state=42).\n",
        "rf_model = ...\n",
        "\n",
        "# TODO: Fit the model on the training data.\n",
        "...\n",
        "\n",
        "print(\"‚úÖ Random Forest model trained!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Make predictions and evaluate the Random Forest model.\n",
        "\n",
        "y_pred_rf = ...  # Class predictions\n",
        "y_pred_rf_proba = ...  # Probability predictions\n",
        "\n",
        "# Calculate metrics\n",
        "roc_auc_rf = ...\n",
        "accuracy_rf = ...\n",
        "\n",
        "print(f\"Random Forest Results:\")\n",
        "print(f\"  - ROC-AUC: {roc_auc_rf:.4f}\")\n",
        "print(f\"  - Accuracy: {accuracy_rf:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Display classification report and confusion matrix for Random Forest.\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_pred_rf))\n",
        "\n",
        "# Plot confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "cm_rf = confusion_matrix(y_val, y_pred_rf)\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
        "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "ax.set_title('Random Forest - Confusion Matrix', fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('../figures/rf_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Visualize feature importance from Random Forest.\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': rf_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "# Plot top 15 features\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "top_features = feature_importance.head(15)\n",
        "sns.barplot(data=top_features, x='importance', y='feature', \n",
        "            palette=periospot_palette, ax=ax)\n",
        "ax.set_title('Random Forest - Top 15 Feature Importances', fontweight='bold')\n",
        "ax.set_xlabel('Importance')\n",
        "ax.set_ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.savefig('../figures/rf_feature_importance.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Save the Random Forest results to a new JSON file.\n",
        "\n",
        "results_rf = {\n",
        "    \"model\": \"RandomForest\",\n",
        "    \"roc_auc\": float(roc_auc_rf),\n",
        "    \"accuracy\": float(accuracy_rf),\n",
        "    \"n_estimators\": 100\n",
        "}\n",
        "\n",
        "with open('../results/random_forest_results.json', 'w') as f:\n",
        "    json.dump(results_rf, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ Results saved to results/random_forest_results.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 4. Compare Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Plot ROC curves for both models to compare them.\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "# Logistic Regression ROC curve\n",
        "fpr_lr, tpr_lr, _ = roc_curve(y_val, y_pred_lr_proba)\n",
        "ax.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {roc_auc_lr:.4f})', \n",
        "        color=COLORS['periospot_blue'], linewidth=2)\n",
        "\n",
        "# Random Forest ROC curve\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_val, y_pred_rf_proba)\n",
        "ax.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {roc_auc_rf:.4f})', \n",
        "        color=COLORS['crimson_blaze'], linewidth=2)\n",
        "\n",
        "# Diagonal line (random classifier)\n",
        "ax.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title('ROC Curve Comparison - Baseline Models', fontweight='bold')\n",
        "ax.legend(loc='lower right')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../figures/baseline_roc_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary comparison table\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': ['Logistic Regression', 'Random Forest'],\n",
        "    'ROC-AUC': [roc_auc_lr, roc_auc_rf],\n",
        "    'Accuracy': [accuracy_lr, accuracy_rf]\n",
        "})\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"BASELINE MODELS COMPARISON\")\n",
        "print(\"=\" * 50)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Identify best model\n",
        "best_model = comparison_df.loc[comparison_df['ROC-AUC'].idxmax(), 'Model']\n",
        "print(f\"\\nüèÜ Best baseline model: {best_model}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### ‚úÖ Baseline Models Complete!\n",
        "\n",
        "**Results Summary:**\n",
        "- Logistic Regression: Simple, interpretable baseline\n",
        "- Random Forest: Ensemble method with feature importance\n",
        "\n",
        "**Next Steps:** \n",
        "- Try advanced gradient boosting models in notebooks 04-06\n",
        "- Compare all models to select the best one for submission\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü¶∑ Dental Implant 10-Year Survival Prediction\n",
        "\n",
        "## Notebook 03: Baseline Models (Logistic Regression & Random Forest)\n",
        "\n",
        "**Objective:** Train and evaluate baseline models to establish a performance benchmark. We'll use Logistic Regression and Random Forest as our starting points.\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
